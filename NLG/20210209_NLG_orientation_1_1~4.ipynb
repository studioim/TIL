{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 김기현의 딥러닝을 활용한 자연어생성 올인원 패키지 Online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [01. Chapter1. Orientation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Ch 01. Orientation - 01. Orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Ch 01. Orientation - 02. Stat & Geo Perspective for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<리뷰: statistical & Geometric Perspective for Deep Learning>\n",
    "<이전까지>\n",
    "-우리의 목적은\n",
    "세상에 존재하는 어떤 미지의 함수를 모사하자\n",
    "-주어진 입력에 대해 원하는 출력을 반환하도록 손실함수를 최소화하는 파라미터를 찾자\n",
    "-그레디언트 디센트를 수행하기 위해 역전파를 수행하자\n",
    "\n",
    "<이 수업 이후에는>\n",
    "-우리의 목적은\n",
    "세상에 존재하는 어떤 미지의 확률분포함수를 모사(approximate)하자\n",
    "\n",
    "+Probabilistic Perspective\n",
    "확률 분포 P(x)와 P(y|x)로부터 데이터를 수집해\n",
    "해당 데이터를 가장 잘 설명하는 확률분포함수의 파라미터 세타를 찾자: logP(y|x;세타)\n",
    "\t-MLE\n",
    "\t-Gradient Descent using Back-propagation\n",
    "또는 두 확률 분포를 비슷하게 만들자\n",
    "\t-Minimize Cross Entropy(or KL-Divergence)\n",
    "\n",
    "+Geometric Perspective\n",
    "데이터란 저 차원의 manifold에 분포하고 있으며, 여기에 약간의 노이즈 엡실론이 추가돼 있는 것\n",
    "\t-노이즈란 태스크(x->y)에 따라서 다양하게 해석 가능할 것\n",
    "따라서 해당 매니폴드를 배울 수 있다면, 더 낮은 차원으로 효율적인 맵핑(또는 project)이 가능\n",
    "\t-Non-linear dimension reduction 비선형 차원축소\n",
    "\t-예. 오토 인코더\n",
    "\n",
    "+Representation Learning, Again\n",
    "낮은 차원으로 맵핑하는 과정에서 피처를 자연스럽게 학습하게 된다.\n",
    "낮은 차원으로의 표현을 통해, 차원의 저주(curse of dimensionality)를 벗어나 효과적 학습이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Ch 01. Orientation - 03. Review Introduction to NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "리뷰: NLP Introductions\n",
    "<리뷰: 오토인코더>\n",
    "-인코더와 디코더를 통해 압축과 해제를 실행\n",
    "인코더는 입력(x)의 정보를 최대한 보존하도록 손실 압축을 수행\n",
    "디코더는 중간 결과물(z)의 정보를 입력과 같아지도록 압축 해제(복원) 수행\n",
    "-복원을 성공적으로 하기 위해 오토인코더는 특징을 추출하는 방법을 자동으로 학습\n",
    "중요한 정보 남겨두고 쓸모없는 것부터 버릴 것.\n",
    "\n",
    "<In Word2Vec>\n",
    "-목표: 주어진 단어로 주변 단어를 예측하자\n",
    "스킵그램, 씨보우\n",
    "-y를 예측하기 위해 필요한 정보가 z에 있어야 한다\n",
    "주변 단어를 잘 예측하기 위해 x를 잘 압축하자.\n",
    "\n",
    "<In Text Classififcation>\n",
    "Using RNN\n",
    "Using CNN\n",
    "\n",
    "<Wrap-up>\n",
    "-신경망은 x와 y 사이의 관계를 학습하는 과정에서 피처를 자연스럽게 학습\n",
    "특히 저차원으로 축소(압축)되는 과정에서 정보의 취사/선택이 이뤄짐\n",
    "-워드 임베딩(스킵그램):\n",
    "주변 단어(y)를 예측하기 위해 필요한 정보를 현재 단어(x)에서 추출해 압축\n",
    "-센텐스 임베딩(text classification):\n",
    "Label(y)을 예측하기 위해 필요한 정보를 단어들의 시퀀스(x)로부터 추출해 압축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Ch 01. Orientation - 04. 자연어 생성이란"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<우리의 목적>\n",
    "-컴퓨터가 인간이 만들어 놓은 대량의 문서를 통해 정보를 얻고(NLU)\n",
    "-얻어낸 정보를 사람이 이해할 수 있게 사람의 언어로 표현하는 것(NLG)\n",
    "\n",
    "<before Sequence-to-Sequence>\n",
    "NLP는 다른 분야에 비해 늦게 딥러닝 도입\n",
    "-워드 임베딩[Mikolov et al., 2013]\n",
    "-텍스트 분류[Kim, 2014]\n",
    "-> Text to Numeric values\n",
    "\n",
    "<After Seq-to-Seq with Attention>\n",
    "-Beyond “text to numeric”\n",
    "-numeric to text 가능해져\n",
    "물론 어떤 숫자를 넣어야 어떤 글이 나온다라는 것은 알 수 없다. 완벽히 컨트롤 할 수 있는 상황 아냐. 블랙박스.\n",
    "\n",
    "<Era of Attention>\n",
    "-트랜스포머의 등장으로 인해 연구는 더더욱 가속\n",
    "PLM(Pretrained Language Model)의 유행으로 인해 NLG 뿐만 아니라 NLP의 다른 영역에도 큰 영향\n",
    "-거스를 수 없는 대세, PLM\n",
    "트랜스포머는 NLG를 위해서 만들어진 아키텍처\n",
    "이 수업은 PLM을 제대로 다루기 위한 Step-stone(징검다리)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: [02. Chapter2. Language Modeling] 01. Ch 02. Language Modeling - 01. 들어가며"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
