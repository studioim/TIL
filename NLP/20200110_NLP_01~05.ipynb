{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Part2. 자연어처리 입문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Ch 02. Introduction - 01. 자연어처리란 무엇인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "언어는 무엇인가?\n",
    "사람들 간 정보 전달 위한 체계\n",
    "언어는 이산적 데이터(연속적 데이터 아님)\n",
    "\n",
    "인터페이스 투 AI\n",
    "사람의 생각(의도, 정보)을 컴퓨터에게 전달하는 방법\n",
    "\n",
    "나이브 인터페이스\n",
    "사람이 이해할 수 있지만 엄격한 문법과 모호성이 없는 형태의 전달 방식\n",
    "인공언어: 프로그래밍언어\n",
    "\n",
    "베터 인터페이스\n",
    "사람이 실제 사용하는 형태에 가까운 전달 방식\n",
    "자연언어\n",
    "\n",
    "<자연어 처리란?>\n",
    "자연어란?\n",
    "자연어 혹은 자연언어는 사람들이 일상적으로 쓰는 언어를 인공적으로 만들어진 언어인 인공어와 구분해 부르는 개념\n",
    "자연어처리\n",
    "사람이 이해하는 자연어를 컴퓨터가 이해할 수 있는 값으로 바꾸는 과정(NLU)\n",
    "더 나아가 컴퓨터가 이해할 수 있는 값을 사람이 이해하도록 바꾸는 과정(NLG)\n",
    "\n",
    "사람의 언어를 이해하게 되면 지금과 같이 특정 태스크에만 잘 동작하는 인공지능이 아니라 제너럴한 실제 지능이라고 할 수 있는 인공지능이 만들어질 수 있다고 이야기도 함.\n",
    "다음 인공지능을 만들어내는 데서 가장 큰 역할을 하는 것이 자연어처리가 될 것이라고 말하는 사람들이 있다.\n",
    "\n",
    "연구 분야\n",
    "NLG 생성 -> 딥러닝에서 꽃을 피우고 있다.\n",
    "Language Modeling, Article Generation\n",
    "NLU 이행\n",
    "Text classification, POS Tagging, Sentiment Analysis, Machine Reading Comprehension, Named Entity Recognition. Semantic Parsing\n",
    "NLG 교집합 NLU\n",
    "Chatbot\n",
    "Summarization\n",
    "Question Answering\n",
    "Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Ch 02. Introduction - 02. NLP with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "전통적인 NLP\n",
    "단어를 심볼릭 데이터로 취급 - 원핫벡터로 표현을 하는데 그러면 서로간의 관계를 구별할 수 없다.(데이터 희소성 문제?)\n",
    "여러 sub-module을 통해 전체 구성 - 전체적으로 무겁다. 모델을 거듭할수록 정확도가 떨어진다.\n",
    "\n",
    "NLP with 딥러닝\n",
    "단어를 컨티뉴어스 밸류로 변환\n",
    "엔드투엔드 시스템 추구\n",
    "\n",
    "<전통적 자연어처리의 특징>\n",
    "심볼릭 기반 접근\n",
    "(전통적 심볼릭 기반 접근 방법)/(딥러닝 기반 접근 방법)\n",
    "이산적, 심볼릭 공간 - 연속적, 신경망 공간\n",
    "사람이 인지 쉬움 - 사람이 이해하기 어려움\n",
    "디버그 용이 - 디버깅 어려움\n",
    "연산 속도 느림 - 연산 속도 빠름\n",
    "모호성과 유의성에 취약함 - 모호성과 유의성에 강인함\n",
    "여러 서브 모듈이 폭포수 형태를 취하므로 특징 추출에 노력이 필요 - 엔드투엔드 모델을 통한 성능 개선과 시스템 간소화 가능\n",
    "여러 단계의 sub-module 구성\n",
    "무거움\n",
    "각 모듈의 오류가 이후 모듈에 영향을 끼침(error propagation)\n",
    "\n",
    "블랙박스와 같은 딥러닝\n",
    "XAI(explainable AI) 연구 많이 한다.\n",
    "\n",
    "<NLP system with deep learning>\n",
    "사람이 이해할 수 있는 이산적 심볼릭 데이터 -> 연산효율 높은 연속데이터(by 임베딩 계층 / 인코더) -> 신경망 내부 연산 -> 연속데이터를 심볼릭 데이터로 (By 생성 계층 / 디코더)\n",
    "\n",
    "<패러다임 시프트 in 자연어 처리>\n",
    "1950s Rule-based - 1990s Statistical(Word-based, Phrased-based) - 2015 Neural\n",
    "\n",
    "효율적 임베딩을 통한 성능 개선\n",
    "단어 문장 컨텍스트 임베딩\n",
    "\n",
    "엔드투엔드 구성으로 인한 효율/성능 개선\n",
    "가볍고 빠르다\n",
    "\n",
    "결국 기계 번역의 경우, 다른 분야에 비해 가장 먼저 성공적인 상용화\n",
    "딥러닝의 NLP 적용은 가장 늦게 됐다.\n",
    "딥러닝 시대의 NLP는 워드 임베딩이나, 텍스트 분류 정도에서 나아가지 못하고 있었는데 2015년 시퀀스투시퀀스 나오게 되면서 다른 분야에 비해 가장 먼저 성공적인 사용화가 이뤄짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Ch 02. Introduction - 03. 자연어처리와 다른 분야의 차이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<AI 삼대장(+1?)>\n",
    "- 컴뷰터 비전 : Image Recognition, Object Detection, Image Generation, super Resoultion\n",
    "- 자연어 처리: 텍스트 분류, 머신 트랜스레이션, 서머라이제이션, question Answering\n",
    "- Speech Processing : Speech Recognition(STT, speech to text), Speech Synthesis(TTS, Text To Speech), Speaker Identification\n",
    "강화 학습\n",
    "\n",
    "<NLP vs Others>\n",
    "- 자연어처리\n",
    "Discrete value를 다룸(단어, 문장)\n",
    "분류 문제로 접근할 수 있음\n",
    "샘플의 확률 값을 구할 수 있음 P(X = 단어)\n",
    "문장생성(자연어 생성)\n",
    "auto-regressive 속성(과거의 값이 현재의 값에 영향)을 지님\n",
    "GAN 적용 불가(디스크릿한 속성 떄문에)\n",
    "\n",
    "Other Fields(e.g. 컴퓨터 비전)\n",
    "컨티뉴어스 밸류를 다룸(이미지, 음성)\n",
    "문제에 따라 접근 방식이 다름\n",
    "샘플의 확률 값을 구할 수 없음 P(X = 이미지)\n",
    "이미지 생성\n",
    "auto-regressive 속성 없음\n",
    "GAN 적용 가능(갠은 이미지를 위해 나왔다)\n",
    "\n",
    "<NLP research requirees>\n",
    "Domain Knowledge : 언어직 지식 필요\n",
    "Nasty Preprocessing(더러운 전처리) : 태스크에 따른 정제(normalization) 과정 필요\n",
    "결국 가장 큰 성능 차이는 데이터의 양과 품질이 된다. 데이터를 얼마나 많이 모았고, 잘 정제했는지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Ch 02. Introduction - 04. 왜 자연어처리는 어려운가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Ambiguity(모호성)>\n",
    "- 차를 마시러 공원에 가던 차 안에서 나는 그녀에게 차였다.\n",
    "이처럼 모호한 문장 번역 어려움\n",
    "-> 중의성 해소(word sense disambiguation WSD)\n",
    "주변 단어를 보면 중의성을 해소할 수 있다.\n",
    "\n",
    "- 나는 철수를 안 때렸다\n",
    "철수는 맞았지만, 때린 사람이 나는 아니다\n",
    "나는 누군가를 때렸지만, 그게 철수는 아니다\n",
    "나는 누군가를 때린 적도 없고, 철수도 맞은 적이 없다.\n",
    "-> 문장 내 정보의 부족으로 인한 모호성이 발생\n",
    "\n",
    "<왜 언어는 모호성을 가지나?>\n",
    "- 언어는 마치 생명체와 같이 진화하며, 특히 효율성을 극대화하는 방향으로 진화\n",
    "따라서 최대한 짧은 문장 내에 많은 정보를 담고자 한다.\n",
    "정보량이 낮은 내용(context)은 생략\n",
    "여기에서 모호함(ambiguity)이 발생\n",
    "오토인코더도 마찬가지\n",
    "생략된 컨텍스트를 인간은 효율적으로 채울 수 있지만, 기계는 이러한 태스크에 매우 취약\n",
    "\n",
    "<Paraphrase 다른 말로 바꾸어 표현하다>\n",
    "여자가 김치를 어떤 남자에게 집어 던지고 있다.\n",
    "여자가 어떠 남자에게 김치로 때리고 있다.\n",
    "여자가 김치로 싸대기를 날리고 있다.\n",
    "-> 문장의 표현 형식은 다양하고, 비슷한 의미의 단어들이 존재하기 때문에\n",
    "paraphrase의 문제가 존재.\n",
    "\n",
    "<Discrete, not Continuous>\n",
    "- 이산 값을 갖는 자연어는 사람의 입장에서 인지가 쉬울 수 있으나,\n",
    "기계의 입장에서는 매우 어려운 값.\n",
    "One-hot 인코딩으로 표현된 값은 유사도나 모호성을 표현할 수 없다.\n",
    "서로 다른 원핫 벡터끼리의 유사도나 거리는 모두 동일하다.\n",
    "따라서, 아래의 질문에 대답할 수 없다\n",
    "파랑과 핑크 중에서 빨강에 가까운 단어는 무엇인가?\n",
    "하지만 사람의 어휘 체계는 계층적 구조를 띄고 있다.\n",
    "또한 높은 차원으로 표현돼 매우 sparse하게 된다.\n",
    "-> 딥러닝에서는 워드 임베딩을 통해 해결\n",
    "\n",
    "<요약>\n",
    "Ambiguity\n",
    "Paraphrase\n",
    "Discrete, not Continuous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
