{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23. Ch 04. Geometric Perspective - 05. 정리하며"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<이 수업 전에는>\n",
    "-우리의 목적은\n",
    "세상에 존재하는 어떤 미지의 함수를 모사하자\n",
    "-주어진 입력(x)에 대해서 원하는 출력(y)을 반환하도록\n",
    "손실함수를 최소화하는 파라미터(세타)를 찾자\n",
    "-그레디언트 디센트를 수행하기 위해 역전파(백프로퍼게이션)를 수행하자\n",
    "\n",
    "<이 수업 이후에는>\n",
    "-우리의 목적은\n",
    "세상에 존재하는 어떤 미지의 확률 분포 함수를 모사(approximate)하자\n",
    "-확률적 관점에서 봤을 때\n",
    "확률분포 P(x)와 P(y|x)로부터 데이터를 수집해\n",
    "해당 데이터를 가장 잘 설명하는 확률 분포 함수의 파라미터 세타를 찾자: logP(y|x;세타)\n",
    "\t->MLE\n",
    "\t->NLL 최소화\n",
    "\t->Gradient Descent using Back-propagation\n",
    "또는 두 확률 분포를 비슷하게 만들자\n",
    "\t-Minimize Cross Entropy(or KL-Divergence)\n",
    "-Geometric Perspective\n",
    "데이터란 저차원의 매니폴드에 분포하고 있으며, 여기에 약간의 노이즈(엡실론)가 추가돼 있는 것\n",
    "\t-노이즈란 태스크(x -> y)에 따라서 다양하게 해석 가능할 것\n",
    "\t-MNIST 분류의 노이즈와 오토인코더의 노이즈는 다르다\n",
    "-따라서 해당 매니폴드를 배울 수 있다면, 더 낮은 차원으로 효율적 맵핑(or project)이 가능\n",
    "\t-Non-linear dimension reduction 비선형차원축소\n",
    "-Representation Learning, Again\n",
    "낮은 차원으로의 표현을 통해,\n",
    "차원의 저주(curse of dimensionality)를 벗어나 효과적인 학습이 가능\n",
    "우리는 차원의저주를 훨씬 더 효율적으로 어느 정도 해결할 수 있다.\n",
    "\n",
    "<결론>\n",
    "-DNN은 굉장히 유연한 함수이기 떄문에 다양한 관점에서 해석이 가능\n",
    "-따라서 대부분의 새롭게 제시되는 방법들은 위의 관점에서 설계되고 제안된 것\n",
    "-위의 관점에서 딥러닝을 바라본다면 훨씬 쉽게 이해할 수 있을 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24. Ch 05. Advanced PyTorch Tutorials - 01. PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<What we need to do>\n",
    "-1.Read & Split\n",
    "\t-1)Read tabular dataset(e.g. csv file)\n",
    "\t-2)Shuffling before split into train/valid/test set\n",
    "\t-3)Split train, valid and test set\n",
    "-2.Preprocessing\n",
    "\t-1)Remove unnecessary rows(e.g. high null ratio)\n",
    "\t-2)Standard or Min/Max Scaling based on training set.\n",
    "\t\t-트레인셋 기준으로 뮤와 시그마가 각 피처별로 나오고 해당 뮤와 시그마를 검증 테스트 셋에 똑같이 적용해야 함.\n",
    "-3.Iterator\n",
    "\t-1)Suffle for each epoch.\n",
    "\t-2)Get tensor chunk with mini-batch size\n",
    "\t-3)Yield the mini-batch for each iteration\n",
    "\n",
    "-> 1.2는 Dataset, 3은 DataLoader\n",
    "이러한 과정을 반복하게 되는데\n",
    "코드의 통일성, 재사용성을 위해서 파이토치에서 제공하는 클래스를 써서 데이터를 맵핑하고 자동으로 이터레이티브하게 리턴해주는 작업을 한다.\n",
    "다른 사람들도 어려움 없이 쓸 수 있게 된다.\n",
    "\n",
    "<Plug & Play>\n",
    "-torch.utils.data.DataSet\n",
    "\t-__init__(self, *args, **kwargs) : 데이터를 읽어오기\n",
    "\t-__len__(self) : 데이터의 크기 알기\n",
    "\t-__getitem__(self, idx) : 전처리 및 미니배치를 위한 샘플 반환\n",
    "-torch.utils.data.DataLoader : 셔플링, 미니배치 구성, Yield\n",
    "패키지 안에 들어 있다.\n",
    "기존의 프레임워크 안에서 수행할 수 있어\n",
    "굉장히 간편하게 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : 08. Ch 02. Representation Learning - 05. 실습 오토인코더\n",
    "## 25. Ch 05. Advanced PyTorch Tutorials - 02. 실습 PyTorch Dataset을 활용하여 구현하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
