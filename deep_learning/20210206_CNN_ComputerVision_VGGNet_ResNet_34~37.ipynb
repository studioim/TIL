{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 34. Ch 06. Convolutional Neural Networks - 07. 정리하며"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-딥러닝 이전에는\n",
    "컨볼루션 필터를 활용해 핸드크래프트 피처 추출\n",
    "-딥러닝 시대에서는\n",
    "x -> y 관계의 학습에서 필요한 피처를 추출하기 위한 컨볼루션 필터를 자동으로 학습\n",
    "\n",
    "<FCL과의 비교>\n",
    "-매우 빠르고 적은 웨이트 파라미터를 가짐\n",
    "-입출력 크기가 계산이 까다로워 네트워크 구성이 쉽지 않다\n",
    "3X3커널을 활용하면 그래도 좀 낫다.\n",
    "FCL은 입출력 사이즈 고정\n",
    "\n",
    "<How to design CNN Architecture>\n",
    "-CNN블록\n",
    "3X3컨볼루션 레이어-렐루-배치놈-3X3컨볼루션레이어(+2X2 스트라이드)-렐루-배치놈-맥스풀링\n",
    "채널 수는 늘어나면서 이미지 피처맵의 사이즈는 줄어드는 형태로 네트워크 구성\n",
    "\n",
    "<Wrap-up>\n",
    "-컴퓨터 비전 분야에서 CNN은 뗄 수 없는 존재\n",
    "-패턴 인식에서 워낙 월등함, NLP 등 다른 분야에도 활발히 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 35. Ch 07. Computer Vision Introductions - 01. 영상 처리 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<컴퓨터 비전이 어려운 이유>\n",
    "사람이 보기에도 어려운 문제가 있다.\n",
    "개와 빗자루\n",
    "개와 치킨\n",
    "치와와와 머핀\n",
    "\n",
    "데이터셋의 편향이 있다.\n",
    "제일 많은 게 백인 남자…\n",
    "\n",
    "조명의 위치에 따라서 굉장히 다양한 경우의 수가 생기기도 한다.\n",
    "\n",
    "<딥러닝 역사와 함께>\n",
    "-2012년 이미지넷의 우승 이후, 딥러닝이 큰 주목\n",
    "알렉스넷(8개 층)으로 우승… 딥러닝 시대 활짝\n",
    "딥러닝의 역사는 곧 컴퓨터비전의 역사라고 할 수 있을 정도로…\n",
    "연구도 활발\n",
    "2015년에는 레스넷 152개 layer로 우승\n",
    "그 이후에는 Image Recognition(이미지 분류)이 아닌 GAN, 이미지 생성에 대한 연구들이 많이 이뤄짐\n",
    "\n",
    "<컴퓨터 비전>\n",
    "이미지 Classification: 이미지 넷, 어노멀리 디텍션(Outlier 탐지), Out of Distributions(예. MNIST 데이터셋에서 사람 얼굴)\n",
    "Object Detection: Fast R-CNN, YOLO\n",
    "Image Segmentation: Fully Convolutional Networks(FCN), UNet / 자율주행에서 굉장히 중요\n",
    "Image Generation: Generative Models(예. GAN), Super Resolution\n",
    "\n",
    "이미지 세그멘테이션은 픽셀 단위로 구분을 하지만 오브젝트 디텍션처럼 클래스를 세분할 필요는 없을 수 있다.\n",
    "이미지 세그멘테이션은 픽셀 단위로 레이블링이 필요하기 때문에 차원축소를 해서 끝나면 안 된다.\n",
    "기존의 이미지 분류나 오브젝트 디텍션의 경우 분류는 소프트맥스 값, 디텍션은 위치 정보가 나오면 됨. 차원 축소 가능.\n",
    "그래서 이미지 세그멘테이션은 다른 아키텍처를 많이 사용한다.\n",
    "\n",
    "현재 컴퓨터 비전의 꽃은 이미지 생성\n",
    "세상에 존재하지 않는 사람들의 이미지도 생성 가능\n",
    "\n",
    "<이번 챕터에서는>\n",
    "-이미지넷에서 우승을 했던 프리트레인 된 모델(Backbone network)을 다운을 받아\n",
    "VGGNet, ResNet\n",
    "-전이학습(Transfer Learning)을 통해서 이미지 분류의 성능을 끌어올린다.\n",
    "Big Dataset(예. 이미지넷) - Pretraining -> 프리트레인된 네트워크 -> Load Weights -> 전이학습된 네트워크 <- Fine-tuning - Target Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 36. Ch 07. Computer Vision Introductions - 02. VGG 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Backbone network: VGGNet>\n",
    "백본은 정해져 있는, 널리 쓰이는 아키텍처를 말한다.\n",
    "네트워크 약간 변형 혹은 그대로 사용하기도 한다.\n",
    "하이퍼파라미터 튜닝하거나 연구하는 노력 줄어듦.\n",
    "\n",
    "<소개>\n",
    "-VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION(Simonyan et al., 2014)\n",
    "-2014년 이미지넷 대회에서 2등(GoogLeNet이 1등)\n",
    "2등에도 불구하고 편리하고 가벼운 사용성으로 인해 인기\n",
    "-VGG16(블록 16개), VGG19(블록 19개)와 같이 다양한 버전이 존재\n",
    "쉽고 직관적인 아키텍처\n",
    "\n",
    "<Motivations>\n",
    "-기존 네트워크들은 5X5(25개의 웨이트 파라미터) 또는 7X7(49개의 웨이트 파라미터) conv. layer를 사용\n",
    "레이어를 거칠 때마다, 피처 맵의 축소 발생\n",
    "-3X3 cone. layer를 반복 사용해 5X5 또는 7X7 conv. layer를 대체 가능\n",
    "3X3 2번(웨이트 파라미터 18개) -> 5X5 컨볼루션 레이어\n",
    "3X3 3번(27개) -> 7X7 컨볼루션 레이어\n",
    "- +1 패딩을 활용하면 피처 맵의 크기 유지 가능\n",
    "-결과적으로 더 적은 파라미터로 더 깊은 네트워크 달성 가능\n",
    "더 적은 웨이트로 더 큰 capacity를 달성\n",
    "네트워크가 깊어질수록 캐퍼서티 늘어나고 더 좋은 성능 내는 것을 알고 있음.\n",
    "\n",
    "<From Big Conv. Layer to Small Conv. Layer>\n",
    "3X3 2번(웨이트 파라미터 18개) -> 5X5 컨볼루션 레이어\n",
    "3X3 3번(27개) -> 7X7 컨볼루션 레이어\n",
    "\n",
    "<Methodology 방법론>\n",
    "MNIST Classifier도 VGG 네트워크와 상당히 유사한 구조를 가지고 있음\n",
    "1)3X3 conv. layer + 1 padding(입출력 사이즈 안 바뀜)\n",
    "2)활성함수 + BN(배치놈, 붙여주면 좋다, 당시에는 발명 안 됐었음)\n",
    "3)필요에 따라 1~2번 반복\n",
    "4)2X2 맥스풀링\n",
    "-맥스풀링은 스트라이드로 대체 가능\n",
    "-더 깊지만 더 적은 파라미터를 가진 네트워크(더 직관적)\n",
    "CNN 여러개 쌓으면 끝\n",
    "\n",
    "<요약>\n",
    "-가볍고 편리해 많은 분야에 다양하게 활용\n",
    "예. 오브젝트 디텍션, 이미지 세그멘테이션\n",
    "-마지막의 FC layer는 단점으로 지적됨(이 부분에서 파라미터 많이 들어감. 부담.)\n",
    "\n",
    "이미지넷을 프리트레인한 VGG 네트워크를 가지고 우리의 데이터셋에 적용했을 때 더 높은 성능을 보여주는 것을 실습할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 37. Ch 07. Computer Vision Introductions - 03. ResNet 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Backbone network: ResNet>\n",
    "Deep Residual Learning for Image Recognition(He et al., 2015): skip connections(그냥 ResNet)\n",
    "Identity Mappings in Deep Residual Networks(He et al., 2016): identity skip connections(ResNet 업그레이드)\n",
    "VGGNet에 이어서 2015년 이미지넷 우승\n",
    "Residual Connection이라는 방법 제안\n",
    "그레디언트 배니싱 없이 효율적으로 네트워크 깊게 쌓을 수 있는 방법 제안\n",
    "152층이라는 어마어마한 층을 쌓아 우승\n",
    "\n",
    "<Motivations>\n",
    "-이미지넷 대회가 거듭될수록, 깊은 네트워크가 우승을 차지함\n",
    "-깊은 네트워크를 학습시키는 데 애로사힝이 많음\n",
    "최적화 문제: Training loss가 잘 낮아지지 않음(기울기 소실 문제가 가장 크지만)\n",
    "\n",
    "시그모이드 대신 ReLU를 쓰지 않냐고 할 수도 있지만 \n",
    "ReLU도 음수 부분은 그레디언트가 1보다 작음\n",
    "시그모이드에 비해 기울기 소실 문제가 완화됐다는 것이지 완벽하게 해결된 것은 아님.\n",
    "\n",
    "-데이터의 복잡도에 따라 최적의 깊이가 존재할 텐데, 깊어지면 나머지는 identity 함수면 될 것 아닌가?\n",
    "그렇게 되도록 학습하면 될텐데 왜 못 가지? 거기에 대해서 고민하기 시작\n",
    "\n",
    "<Methodology>\n",
    "-F(x) = H(x) - x\n",
    "-H(x) = F(x) + x\n",
    "기존에는 F만 존재하던 상태\n",
    "F(x) = BN -> ReLU -> weight -> BN -> ReLU -> weight\n",
    "F가 아이덴터티로 가야한다는 건데 이게 쉽지 않다\n",
    "이를 쉽게 만들기 위해 H를 만듦.\n",
    "F가 0이 되면 됨.\n",
    "H(x)에서 x를 뺀 것이기 떄문에 residual(잔차) connection이라고 함.\n",
    "\n",
    "<Methodology>\n",
    "-Residual Block을 쌓자\n",
    "차원축소 되는 부분에서는 residual을 더할 때 차원 축소 이후에 더한다.(F(x)와 x의 차원을 맞춰줘야 하기 때문)\n",
    "34-layer plain보다 34-layer residual이 성능이 월등히 좋아짐\n",
    "\n",
    "<평가>\n",
    "-기존: 레이어가 깊어질수록 낮은 성능\n",
    "-ResNet: 레이어가 깊어질수록 높은 성능\n",
    "\n",
    "<Later, it turns out>\n",
    "-ResNet은 기울기 소실을 방지하는 방법(거의 완벽하게 방지됨)\n",
    "첫 논문 써놓고 보니 기울기 소실 방지에 탁월!\n",
    "나중에는 1000개도 쌓는다\n",
    "\n",
    "-다른 그레디언트 배니싱 방지 방법\n",
    "Hightway Networks(Srivastava et al., 2015)\n",
    "Linear Gated Unit(Dauphin et al., 2016)\n",
    "\n",
    "기울기 소실을 방지하는 방법은 여러가지가 있다.\n",
    "RNN에서는 LSTM을 가지고 기울기 소실 방지\n",
    "\n",
    "-현재 제안되는 대부분의 큰 네트워크들은 레지듀얼 커넥션을 차용\n",
    "예. 트랜스포머(자연어처리 지배!)\n",
    "big language model 학습을 위해서는 깊고 넓게 쌓아야 하기 때문에 레지듀얼 커넥션이 무조건 들어가야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : 38. Ch 07. Computer Vision Introductions - 04. 전이학습(transfer learning) 소개"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
