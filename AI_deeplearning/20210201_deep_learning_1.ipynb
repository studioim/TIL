{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "인공지능(사람 행동 모방) > 기계학습(데이터로부터 학습) > 딥러닝(인공신경망 기반, 많은 양의 데이터를 학습)\n",
    "\n",
    "머신러닝은\n",
    "특징 추출기(feature extractor)에서 사람이 직접 특징벡터 추출\n",
    "이를 분류기에 넣어 구분(학습)\n",
    "\n",
    "딥러닝은\n",
    "특징추출도 분류도 컴퓨터가 모두 알아서 한다\n",
    "\n",
    "딥러닝으로 할 수 있는 일\n",
    "분류, 회귀, 물체 검출(오브젝트 디텍션)-원샷디텍션\n",
    "영상분할(이미지 세그멘테이션), 영상 초해상도(이미지 슈퍼 레졸루션)\n",
    "예술적 창조물(아티스틱 크리에이션 위드 갠)\n",
    "강화학습\n",
    "\n",
    "딥러닝은 2010년도에 대중화. 2006년 제프리 힌턴 교수가 프리트레이닝 방법을 발표하면서 정착(딥뉴럴네트워크)\n",
    "\n",
    "딥러닝 계층이 깊어질수록 학습이 어려운 기울기 소실(배니싱 그레디언트) 문제 발생 후 두 번째 에이아이 윈터\n",
    "이후 서포트벡터머신(얕은 신경망)이 인기를 얻음. 심층믿음신경망으로 해결\n",
    "\n",
    "페이페이리 교수의 대규모 영상 분류 데이터셋 이미지넷\n",
    " \n",
    "클라우드 플랫폼의 대중화 : IaaS - PaaS - SaaS\n",
    "\n",
    "딥러닝 적용분야\n",
    "자율주행, 스마트팜, 스마트팩토리, 추천, 챗봇, 인공지능 IP카메라\n",
    "\n",
    "딥러닝 실습 환경 소개\n",
    "하이퍼파라미터 설정 - 네트워크 구조 정의 - 학습 루프 정의 - 테스트 루프 정의 \n",
    "- 데이터셋 가져오고 정리(정규화, 차원 맞추기, 셔플, 배치) - 네트워크 생성 \n",
    "- 손실함수, 최적화 알고리즘 정의 - 알고리즘 평가지표 설정 - 알고리즘 학습, 테스트 루프\n",
    "\n",
    "신경 세포(뉴런)\n",
    "입력(수상돌기) - 출력(축삭돌기)\n",
    "활성함수는 비선형 특성을 띈다\n",
    "\n",
    "뉴런 / 노드와 엣지\n",
    "\n",
    "인공신경망: 뉴런이 모여 서로 연결된 형태를 인공신경망이라고 부른다. 모든 딥러닝 네트워크는 인공신경망 기반.\n",
    "\n",
    "전결합 계층(Fully-Connected Layer(Dense Layer)): 이전 계층과 모든 뉴런이 서로 연결된 계층을 말한다\n",
    "계층(layer) - 전결합계층\n",
    "\n",
    "얕은 신경망(Shallow Neural Network)\n",
    "처음에는 ANN, NN으로 표현해줬었는데 딥뉴럴네트워크가 나오면서 이와 구분하기 위해 shallow가 붙음.\n",
    "입력 계층 - 은닉 계층 - 출력 계층,  3가지 계층으로 구성\n",
    "은닉 계층과 출력 계층이 풀리 커넥티드 계층인 모델을 얕은 신경망이라고 한다.\n",
    "얕은 신경망에서는 1개의 은닉 계층만을 사용한다.\n",
    "\n",
    "얕은 신경망으로 무엇을 할 수 있을까?\n",
    "키, 몸무게, 나이 - 기대 수명\n",
    "지역, 집 면적, 건축 년도 - 적정 매매가\n",
    "면접 점수, 실기 점수, 필기 점수 - 당락 여부\n",
    "꽃잎의 너비, 꽃잎의 색깔 - 꽃의 종류\n",
    "\n",
    "입력과 출력 간에 상관성이 있을 경우 이를 학습해 새로운 입력에 대해 출력을 낼 수 있다\n",
    "\n",
    "잡음이 있는 학슴 샘플로부터 규칙을 찾아 연속된 값의 출력을 추정하는 것을 회귀라고 한다.\n",
    "\n",
    "입력 값을 분석해 특정 범주(카테고리)로 구분하는 작업을 분류라고 한다.\n",
    "범주가 2개인 경우 이진분류, 그 이상은 다중 클래스 분류\n",
    "\n",
    "얕은 신경망에 대한 깊은 이해가 깊은 신경망(심층 신경망)에 대한 이해를 도울 것이다.\n",
    "\n",
    "뉴런은 수학적으로 두 벡터의 내적으로 쉽게 표현할 수 있다.\n",
    "\n",
    "FC계층은 여러 개의 뉴런을 한 곳에 모아둔 것으로, Matrix 곱셈 연산으로 표현된다\n",
    "\n",
    "다중선형회귀는 변수가 확장돼 벡터의 내적이 된다\n",
    "\n",
    "직선 - 평면 - 초평면\n",
    "\n",
    "얕은 신경망과 이진분류\n",
    "은닉 계층과 회귀\n",
    "선형적으로 분리되지 않는 class -> 선형적으로 분리되는 은닉계층(특징) -> 로지스틱 회귀\n",
    "입력 space를 기준으로 보면 decision boundary가 곡선이 된다.\n",
    "\n",
    "다중분류 문제\n",
    "원핫인코딩된 벡터는 미리 정해둔 테이블을 이용해 어떤 물체인지 알 수 있다.\n",
    "희소 벡터(sparse vector): 대부분의 값이 0이고 크기가 있는 값이 희소하게 나타나는 벡터\n",
    "희소 표현을 이용해 벡터 전체를 표기하지 않고 숫자 하나로 표현할 수 있다\n",
    "소프트맥스함수는 각 입력의 지수함수를 정규화한 것, 각 출력은 0~1 사이 값을 가짐,\n",
    "모든 출력의 합은 반드시 1, 여러 경우의 수 중 한 가지에 속할 확률을 표현\n",
    "시그모이드는 하나의 입력을 0으로 강제한 2클래스 소프트맥스 함수와 동일.\n",
    "2가지 클래스를 구분하기 위해 1개의 입력을 받는다는 점에 주목\n",
    "교차 엔트로피 오차(CEE), 원핫 인코딩으로 인해 정답인 클래스에 대해서만 오차를 계산.\n",
    "정확히 맞추면 오차가 0, 틀릴수록 오차가 무한히 증가하는 특징이 있다.\n",
    "오차를 내는 과정에서는 정답 클래스만 비교하지만, 다중 클래스 분류의 활성함수인 소프트맥스로 인해 다른 클래스에 대한 학습에도 영향을 준다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
